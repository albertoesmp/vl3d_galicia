{
  "in_pcloud": [
    "/mnt/netapp2/Store_uscciaep/lidar_data/pnoa2/mined/RGBIr_MERGE_1_minmaxnorm.laz"
  ],
  "out_pcloud": [
    "/mnt/netapp2/Store_uscciaep/lidar_data/pnoa2/vl3d/kpc_final_XIrRGB_opt12/T1/*"
  ],
  "sequential_pipeline": [
	{
        "class_transformer": "ClassReducer",
        "on_predictions": false,
        "input_class_names": [
			"miss0", "noclass", "ground", "lowveg", "midveg",
			"highveg", "building", "noise", "miss8", "water",
			"miss10", "miss11", "overlap", "miss13", "miss14",
			"miss15", "miss16", "bridge"
		],
        "output_class_names": ["vegetation", "other", "ignore"],
        "class_groups": [
			["lowveg", "midveg", "highveg"],
			["ground", "building", "water", "bridge"],
			[
				"noclass", "noise", "overlap",
				"miss0", "miss8", "miss10", "miss11", "miss13",
				"miss14", "miss15", "miss16"
			]
		],
        "report_path": "*class_reduction.log",
        "plot_path": "*class_reduction.svg"
	},
    {
        "train": "ConvolutionalAutoencoderPwiseClassifier",
        "training_type": "base",
		"fnames": ["norm_ir", "norm_red", "norm_green", "norm_blue", "ones"],
        "random_seed": null,
        "model_args": {
			"fnames": ["norm_ir", "norm_red", "norm_green", "norm_blue", "ones"],
            "num_classes": 3,
            "class_names": ["vegetation", "other", "ignore"],
            "pre_processing": {
                "pre_processor": "hierarchical_fps",
				"support_strategy_num_points": 50000,
                "to_unit_sphere": false,
            	"support_strategy": "fps",
            	"support_chunk_size": 2000,
            	"support_strategy_fast": true,
                "center_on_pcloud": true,
				"neighborhood": {
                    "type": "sphere",
                    "radius": 50.0,
                    "separation_factor": 0.8
                },
                "num_points_per_depth": [512, 256, 128, 64, 32],				
				"fast_flag_per_depth": [false, false, false, false, false],
				"num_downsampling_neighbors": [1, 16, 8, 8, 4],
				"_num_downsampling_neighbors": [1, 1, 1, 1, 1],
				"num_pwise_neighbors": [32, 16, 16, 8, 4],
				"num_upsampling_neighbors": [1, 16, 8, 8, 4],
				"_num_upsampling_neighbors": [1, 1, 1, 1, 1],
                "nthreads": 32,
                "training_receptive_fields_distribution_report_path": "*/training_eval/training_receptive_fields_distribution.log",
				"_training_receptive_fields_distribution_report_path": null,
                "training_receptive_fields_distribution_plot_path": "*/training_eval/training_receptive_fields_distribution.svg",
				"_training_receptive_fields_distribution_plot_path": null,
                "training_receptive_fields_dir": "*/training_eval/training_receptive_fields/",
				"_training_receptive_fields_dir": null,
                "receptive_fields_distribution_report_path": "*/training_eval/receptive_fields_distribution.log",
				"_receptive_fields_distribution_report_path": null,
                "receptive_fields_distribution_plot_path": "*/training_eval/receptive_fields_distribution.svg",
				"_receptive_fields_distribution_plot_path": null,
                "receptive_fields_dir": "*/training_eval/receptive_fields/",
				"_receptive_fields_dir": null,
                "training_support_points_report_path": "*/training_eval/training_support_points.laz",
                "support_points_report_path": "*/training_eval/support_points.laz"
            },
			"feature_extraction": {
				"type": "KPConv",
				"operations_per_depth": [2, 1, 1, 1, 1],
				"feature_space_dims": [64, 64, 128, 256, 512, 1024],
				"bn": true,
				"bn_momentum": 0.0,
				"activate": true,
				"sigma": [50.0, 50.0, 50.0, 50.0, 50.0, 50.0],
				"kernel_radius": [50.0, 50.0, 50.0, 50.0, 50.0, 50.0],
				"num_kernel_points": [15, 15, 15, 15, 15, 15],
				"deformable": [false, false, false, false, false, false],
				"W_initializer": ["glorot_uniform", "glorot_uniform", "glorot_uniform", "glorot_uniform", "glorot_uniform", "glorot_uniform"],
				"W_regularizer": [null, null, null, null, null, null],
				"W_constraint": [null, null, null, null, null, null]
			},
			"_structure_alignment": {
				"tnet_pre_filters_spec": [64, 128, 256],
				"tnet_post_filters_spec": [128, 64, 32],
				"kernel_initializer": "glorot_normal"
			},
			"features_alignment": null,
			"downsampling_filter": "strided_kpconv",
			"upsampling_filter": "mean",
			"upsampling_bn": true,
			"upsampling_momentum": 0.0,
			"conv1d_kernel_initializer": "glorot_normal",
			"output_kernel_initializer": "glorot_normal",
            "model_handling": {
                "summary_report_path": "*/model_summary.log",
                "training_history_dir": "*/training_eval/history",
                "_features_structuring_representation_dir": "*/training_eval/feat_struct_layer/",
				"kpconv_representation_dir": "*/training_eval/kpconv_layers/",
				"skpconv_representation_dir": "*/training_eval/skpconv_layers/",
                "class_weight": [1, 1, 0],
                "training_epochs": 400,
                "batch_size": 16,
                "checkpoint_path": "*/checkpoint.model",
                "checkpoint_monitor": "loss",
                "learning_rate_on_plateau": {
                    "monitor": "loss",
                    "mode": "min",
                    "factor": 0.1,
                    "patience": 2000,
                    "cooldown": 5,
                    "min_delta": 0.01,
                    "min_lr": 1e-6
                }
            },
            "compilation_args": {
                "optimizer": {
                    "algorithm": "Adam",
                    "learning_rate": {
                        "schedule": "exponential_decay",
                        "schedule_args": {
                            "initial_learning_rate": 1e-3,
                            "decay_steps": 10000,
                            "decay_rate": 0.96,
                            "staircase": false
                        }
                    }
                },
                "loss": {
                    "function": "class_weighted_categorical_crossentropy"
                },
                "metrics": [
                    "categorical_accuracy"
                ]
            },
            "architecture_graph_path": "*/model_graph.png",
            "architecture_graph_args": {
                "show_shapes": true,
                "show_dtype": true,
                "show_layer_names": true,
                "rankdir": "TB",
                "expand_nested": true,
                "dpi": 300,
                "show_layer_activations": true
            }
        },
        "autoval_metrics": ["OA", "P", "R", "F1", "IoU", "wP", "wR", "wF1", "wIoU", "MCC", "Kappa"],
        "training_evaluation_metrics": ["OA", "P", "R", "F1", "IoU", "wP", "wR", "wF1", "wIoU", "MCC", "Kappa"],
        "training_class_evaluation_metrics": ["P", "R", "F1", "IoU"],
        "training_evaluation_report_path": "*/training_eval/evaluation.log",
        "training_class_evaluation_report_path": "*/training_eval/class_evaluation.log",
        "training_confusion_matrix_report_path": "*/training_eval/confusion.log",
        "training_confusion_matrix_plot_path": "*/training_eval/confusion.svg",
        "training_class_distribution_report_path": "*/training_eval/class_distribution.log",
        "training_class_distribution_plot_path": "*/training_eval/class_distribution.svg",
        "training_classified_point_cloud_path": "*/training_eval/classified_point_cloud.laz",
        "_training_activations_path": "*/training_eval/activations.laz",
		"training_activations_path": null
    },
    {
      "writer": "PredictivePipelineWriter",
      "out_pipeline": "*pipe/KPC_T1.pipe",
      "include_writer": false,
      "include_imputer": false,
      "include_feature_transformer": false,
      "include_miner": false,
      "include_class_transformer": false
    }
  ]
}
